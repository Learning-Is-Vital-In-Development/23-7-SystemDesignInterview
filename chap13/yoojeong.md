## 13장: 검색어 자동완성 시스템 설계

### 문제 이해 및 설계 범위 확정

**요구사항**

```
- 빠른 응답 속도 : 사용자가 검색어를 입력함에 따라 자동완성 검색어도 충분히 빠르게 표시되어야 한다. 페이스북의 경우 응답속도를 100 밀리초 이내라고 규정한다. 그렇지 않으면 시스템 이용이 불편해진다.
- 연관성 : 검색어는 사용자가 입력한 단어와 연관성이 있어야 한다.
- 정렬 : 시스템의 계산 결과는 인기도 등의 순위 모델에 의해 정렬되어야 한다.
- 규모 확장성 : 시스템은 많은 트래픽을 감당할 수 있도록 확장 가능해야 한다.
- 고가용성 : 시스템의 일부에 장애가 발생하거나 느려지거나, 예상치 못한 네트워크 문제가 발생해도 시스템은 계속 사용 가능해야 한다.

```

**개략적 규모 추정**

- DAU는 천만명, 평균적으로 한 사용자는 매일 10건의 검색을 수행
- 질의 할 때 평균적으로 20바이트의 데이터를 입력
    - 문자 인코딩 방법은 ASCII를 사용한다고 가정하면 1문자 = 1바이트
    - 질의당 평균 1단어 5글자 x 4개단어 = 20 바이트
- 글자를 입력할 때마다 서버로 요청을 보내므로 평균적으로 1회 검색당 20건의 요청이 백엔드로 전달

```python
# dinner 검색 시

search?q=d
search?q=di
search?q=din
search?q=dinn
search?q=dinne
```
- 대략 초당 24,000건의 QPS 발생 = (10,000,000 x 10 질의 / 일 x 20자 / 24시간 / 3600초)
- 질의 가운데 20% 정도는 신규 검색어 = 매일 0.4GB의 신규 데이터가 시스템에 추가 (10,000,000 x 10 질의 / 일 x 20자 x 20%)

### 개략적인 설계안 제시

**데이터 수집 서비스**

질의가 들어올 때마다 키-값 스토어에 질의와 빈도를 저장하는 빈도 테이블을 생성

![image](https://github.com/rachel5004/23-7-SystemDesignInterview/assets/75432228/e6196950-3005-4b19-950d-4b5acdf811c7)

**질의 서비스**

```sql
SELECT * FROM frequence_table WHERE query LIKE 'prefix%' ORDER BY frequency DESC LIMIT 5;
```

- 검색어와 검색어의 빈도를 저장하는 테이블이 만들어져 있다면 빈도가 가장 높은 5개의 단어가 자동완성으로 제공
- 데이터의 양이 적을 때는 나쁘지 않지만 데이터가 많아지면 병목 현상이 생길 수 있다.

### 상세 설계

**트라이 자료구조**


트라이는 문자열을 찾기 위해 사용되는 자료구조 중 하나

- 트라이는 트리 형태다.
- 루트 노드는 빈 문자열을 나타낸다.
- 각 노드는 글자 하나를 저장한다.
- 자식 노드로, 해당 글자 다음에 등장할 모든 글자를 저장하는 노드를 가질 수 있다. (26개의 노드)
- 각 트리 노드는 하나의 단어, 또는 접두어의 문자열을 나타낸다.

![image](https://github.com/rachel5004/23-7-SystemDesignInterview/assets/75432228/c500f0d3-15a7-4421-9906-4464feb387d6)


- p: 접두어의 길이
- n: 트라이 안에 있는 노드 개수
- c: 주어진 노드의 자식 개수

가장 많이 사용된 질의어 k개는 다음과 같이 찾을 수 있다.

1. 해당 접두어를 표현하는 노드를 찾는다. → O(p)
2. 해당 노드부터 시작하는 하위 트리를 탐색하여, 모든 유효 노드를 찾는다.
(유효한 검색 문자열을 구성하는 노드가 유효 노드다.) → O(c)
3. 유효 노드를 정렬하여 가장 인기있는 검색어 k개를 찾는다. →O(c log c)

총 시간 복잡도는 O(p) + O(c) + O(c log c) = O(c log c)

![image](https://github.com/rachel5004/23-7-SystemDesignInterview/assets/75432228/e959b40e-3968-4fd0-a6f8-97364d76d17b)

최악의 경우 k개를 얻기 위해 모든 트리를 다 검색해야 하므로 다음 두 방법으로 해결
- 접두어의 최대 길이 제한
    - 사용자가 검색창에 긴 검색어를 입력하는 경우는 거의 없으므로 p값의 최대 길이를 제한
    - 이러면 위 1단계의 시간 복잡도는 O(1)
- 노드에 인기 검색어 캐시
    - 각 노드에 k개의 인기 검색어를 저장해두면 트라이를 전체 검색하는 일을 방지 가능
    - 각 노드에 k개의 인기 검색어를 저장해두면 트라이를 전체 검색하는 일을 방지 가능
    - but 저장 공간을 많이 쓰기 때문에 응답속도가 중요한 경우 속도 > 저장 공간 트레이드오프 고려
    - 이러면 위 3단계의 시간 복잡도는 O(1)

이제 시간 복잡도는 O(1) + O(1) + O(1) = O(1)


**데이터 수집 서비스**

- 수천만건의 데이터를 매일 수집할텐데, 그때마다 트라이를 갱신하면 질의 서비스가 심각하게 느려질 것이다.
- 일단 트라이가 만들어지고 나면 인기 검색어는 그다지 자주 바뀌지 않을 것이다. 따라서 너무 자주 갱신할 필요는 없다.


![image](https://github.com/rachel5004/23-7-SystemDesignInterview/assets/75432228/7c1a73f7-2445-47b0-b496-4bdec6206b4a)


| 컴포넌트 | 설명 | 예시 |
|:--:|:--|:--:|
|데이터 분석 서비스 로그|- 검색창에 입력된 질의에 관한 원본 데이터가 보관된다.<br>- Append 로만 데이터가 추가되고, 인덱스를 걸지 않는다.| ![image](https://github.com/rachel5004/23-7-SystemDesignInterview/assets/75432228/2d57d59c-86cc-4efa-8b3c-8e954c028b75)|
|로그 취합 서버|- 원본 데이터를 잘 취합(애그리게이션)하여 취합된 데이터로 만든 뒤, 별도의 저장소로 보관| |
|취합된 데이터|- 로그 취합 서버에 의해 취합된 데이터|![image](https://github.com/rachel5004/23-7-SystemDesignInterview/assets/75432228/a11c50fd-9508-46d0-9355-14a5512220af)|
|작업 서버|- 주기적으로 비동기 작업을 실행하는 서버 집합<br>- 취합된 데이터로부터 트라이를 만들고, DB에 저장한다.| |
|트라이 캐시|- 분산 캐시 시스템으로, 데이터를 메모리에 유지하여 읽기 연산을 높인다.<br>- 주기적으로 DB의 스냅샷을 떠서 갱신| |
|트라이 DB|- 트라이를 저장하는 지속성 저장소다.<br>`구현1 - 문서 저장소(MongoDB..)`<br>  - 새 트라이를 매주 만들 것이므로, 주기적으로 트라이를 직렬화하여 DB에 저장할 수 있다.<br>`구현2 - 키-값 저장소`<br>   - 키(트라이에 보관된 모든 접두어) - 값(각 트라이 노드에 보관된 모든 데이터) |![image](https://github.com/rachel5004/23-7-SystemDesignInterview/assets/75432228/f6be037c-59b2-4aa6-ad29-2f1dba373a3a)|


**질의 서비스**

![image](https://github.com/rachel5004/23-7-SystemDesignInterview/assets/75432228/d21c3317-3b54-44ba-a723-8ec7ef7f0822)

질의 서비스는 빨라야한다

| 최적화 | 설명 | 예시 |
|:--:|:--|:--:|
|AJAX 요청|- 브라우저에서 AJAX요청을 사용하도록 하면, 응답을 받기 위해 새로고침 할 필요가 없다.| |
|브라우저 캐싱|- 자동완성 검색어 제안 결과는 대부분 짧은 시간 안에 자주 바뀌지 않는다.<br>- 제안된 검색어들을 브라우저 캐시에 넣어두면 후속 질의의 결과는 캐시에서 바로 가져갈 수 있다. | 구글 검색엔진<br>![image](https://github.com/rachel5004/23-7-SystemDesignInterview/assets/75432228/d38b21ee-ae0b-44d4-bfdd-86a66cf358a0)|
|데이터 샘플링|- 모든 질의 결과를 로깅해놓으면 CPU와 저장공간을 엄청나게 소모<br>- 모든 요청을 다 로깅하는게 아니라 그 중 일부만 로깅||


**트라이 연산**


| 컴포넌트 | 설명 | 예시 |
|:--:|:--|:--:|
|트라이 생성|트라이 생성은 작업 서버가 담당하며, 취합된 데이터를 이용한다.| |
|트라이 갱신| 주기적으로 한 번 갱신하는 방법 : 주기적으로 새로운 트라이를 만들어 기존 트라이를 대체 <br> 트라이의 각 노드를 개별적으로 갱신하는 방법 : 트라이 노드를 갱신할 때, 상위 노드도 모두 갱신해야 함, 트라이가 작을 때 고려|![image](https://github.com/rachel5004/23-7-SystemDesignInterview/assets/75432228/fdda104d-090a-415e-bdf7-b52ec19233d6)|
|검색어 삭제|일부 질의어(혐오, 폭력, 성적 내용이 포함된)는 자동완성 결과에서 제거<br>이를 위해 트라이 캐시 앞에 필터 게층을 두고 부적절한 질의어 필터링|![image](https://github.com/rachel5004/23-7-SystemDesignInterview/assets/75432228/3a58b157-839b-4a2f-8d86-762ecec4b9e0)|


**저장소 규모 확장**

| 방법 | 설명 |
|:--:|:--|
|첫 글자 기준으로 샤딩| 영어만 지원하면 되기 때문에 첫 글자를 기준으로 샤딩 가능<br>사용 가능한 서버가 최대 26대로 제한|
|두 번째 글자까지 묶어서 샤딩| 위 문제를 해결하기 위해서는 계층적으로 샤딩 <br>but 데이터가 서버에 균등하게 배분되지 않는다<br> ex. “aa” 부터 “ag” 까지는 첫 번째 서버, “ah” - “an” 은 두 번째 서버|
|샤드 맵 매니저로 매핑될 노드 지정| 샤드 맵 매니저가 데이터가 균등하게 배분되도록, 어떤 검색어가 어디로 들어갈지 결정해준다.<br> ex. “u”, “v”, “w” 로 시작하는 노드의 합이, “s” 로 시작하는 노드 하나와 비슷하다면, 각각 두개의 노드로 샤딩|

### 마무리

- 다국어 지원이 가능한 시스템 : 트라이에 유니코드 데이터를 저장
- 국가별로 인기 검색어 순위가 다르다면 : 국가별로 다른 트라이를 사용, 트라이를 CDN에 저장하여 국가별로 응답속도를 높임
- 실시간으로 변하는 검색어 추이 반영
    - 현재의 배치 작업, 트라이는 부적절
    - 샤딩을 통하여 작업 대상 데이터의 양을 줄이고 순위 모델을 바꿔 최근 검색어에 더 높은 가중치를 준다.
    - 스트림 형태의 데이터 처리하기 위해서 `하둡 맵 리듀스`, `아파치 스파크 스트리밍`,`아파치 카프카` 등 고려


